{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "named entity recognition NLP CC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut-XDow6TECx",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "----------------------Task 1----------------------\n",
        "\n",
        "Build a parser that can extract building/business name from a given address.\n",
        "\n",
        "building/business name might appears in various format within an address.\n",
        "\n",
        "Example input address and respective expected building/business name are given in 'sample_building_name_extracted.csv' file\n",
        "\n",
        "Sample Road Name List also provided in 'names_sample.csv'\n",
        "\n",
        "Based on that road list you can train custom road model to extract building/business name given in 'user_raw_data.csv'\n",
        "\n",
        "-------------------------Task 2-----------------------------\n",
        "\n",
        "Build a parser that can extract building/business name from a given address\n",
        "\n",
        "building/business name might appears in various format within an address.\n",
        "\n",
        "Example input address and respective expected road no/road name are given in 'sample_road_name_extracted.csv' file\n",
        "\n",
        "Sample Road Name List also provided in 'roads.csv'\n",
        "\n",
        "Based on that road list you can train custom road model to extract road no/road name given in 'user_raw_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsGptZC2TEC0",
        "colab_type": "code",
        "outputId": "237d507a-ca40-4446-aa43-1d73bd02030b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "# Install extra-dependencies\n",
        "\n",
        "#for downloading extended dependencis\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "! pip -q install git+https://www.github.com/keras-team/keras-contrib.git sklearn-crfsuite\n",
        "! pip install keras==2.2.4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "\u001b[K     |████████████████████████████████| 757kB 4.4MB/s \n",
            "\u001b[?25h  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.17.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "Successfully installed keras-2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jSZ2EQMTEC4",
        "colab_type": "code",
        "outputId": "4528703f-095a-4579-ed80-c6a843a89e49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "#importing all the necessary liaberies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from nltk.tokenize import WordPunctTokenizer, word_tokenize\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "from keras_contrib.layers import CRF\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn_crfsuite.metrics import flat_classification_report"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWo1J_RrU_S0",
        "colab_type": "code",
        "outputId": "2d26a679-fa78-4c4c-cb34-0cd2deb8ca38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import os\n",
        "# mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/Tasks/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewlSMKc9Htqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load all the data for TASK 2:\n",
        "t2_user_name = pd.read_csv('Task2/roads.csv')\n",
        "t2_road = pd.read_csv('Task2/sample_road_name_extracted.csv')\n",
        "t2_raw_user = pd.read_excel('Task2/user_raw_data.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKrjLKQlH0At",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Function to pre process the whole dataset. \n",
        "\n",
        "Taking input the dataframe and returning a list\n",
        "\"\"\"\n",
        "def preProcessData(user_data):\n",
        "  #replacing all \\n to space and other uncessary info from scenence and converted to them in lowercase letter\n",
        "  word_list = []\n",
        "  user_data = user_data.replace({'\\n'},'', regex=True)\n",
        "  user_data = user_data.loc[:, \"address\"].str.lower()\n",
        "  \n",
        "  for i in range(len(user_data)):\n",
        "    tokenized_data = nltk.word_tokenize(user_data.iloc[i])\n",
        "    word_list.append(tokenized_data)\n",
        "  \n",
        "  return word_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiXuSwIuH5UU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#receiving data from preProcessData function\n",
        "processed_data = preProcessData(t2_raw_user)\n",
        "\n",
        "word_list = []\n",
        "sen_list = []\n",
        "counter = 0\n",
        "#loping through all the words for converting it into a list\n",
        "for i in processed_data:\n",
        "  counter = counter + 1\n",
        "  sentence = 'sentence-' + str(counter)\n",
        "  for r in i:\n",
        "    word_list.append(r)\n",
        "    sen_list.append(sentence)\n",
        "\n",
        "dic = {'sentence':sen_list, 'word':word_list}\n",
        "data = pd.DataFrame(dic)\n",
        "\n",
        "data.to_excel(\"pre_processed_output_data.xlsx\", index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYjAR3NeTEC8",
        "colab_type": "text"
      },
      "source": [
        "## Hyperprameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcflPcxiTEC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 256  # Number of examples used in each iteration\n",
        "EPOCHS = 25  # Number of passes through entire dataset\n",
        "MAX_LEN = 15  # Max length of review (in words)\n",
        "EMBEDDING = 40  # Dimension of word embedding vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln92tF3cTEDC",
        "colab_type": "code",
        "outputId": "ed5842e4-75ec-41ad-fbfa-d579529b18f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#Data preview\n",
        "data = pd.read_excel(\"test_file.xlsx\")\n",
        "print(\"Number of sentences: \", len(data.groupby(['Sentence #'])))\n",
        "\n",
        "words = list(set(data[\"Word\"].values))\n",
        "n_words = len(words)\n",
        "print(\"Number of words in the dataset: \", n_words)\n",
        "\n",
        "tags = list(set(data[\"Tag\"].values))\n",
        "print(\"Tags:\", tags)\n",
        "n_tags = len(tags)\n",
        "print(\"Number of Labels: \", n_tags)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences:  1450\n",
            "Number of words in the dataset:  3924\n",
            "Tags: ['B-BLD', 'O', 'I-RAD', 'B-RAD', 'I-BLD']\n",
            "Number of Labels:  5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "189JTeNoTEDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceGetter(object):\n",
        "    \"\"\"Class to Get the sentence in this format:\"\"\"\n",
        "\n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        healper_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(), s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(healper_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        \"\"\"Return one sentence\"\"\"\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None\n",
        "getter = SentenceGetter(data)\n",
        "sent = getter.get_next()\n",
        "\n",
        "# Get all the sentences\n",
        "sentences = getter.sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_k6hyseTEDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "using the `word2idx` dictionary to convert each word to a corresponding integer ID \n",
        "\"\"\"\n",
        "word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
        "word2idx[\"UNK\"] = 1 # Unknown words\n",
        "word2idx[\"PAD\"] = 0 # Padding\n",
        "idx2word = {i: w for w, i in word2idx.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs2u66HfTEDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Using the `tag2idx` to convert each tags to a corresponding integer ID\n",
        "\"\"\"\n",
        "tag2idx = {t: i+1 for i, t in enumerate(tags)}\n",
        "tag2idx[\"PAD\"] = 0\n",
        "idx2tag = {i: w for w, i in tag2idx.items()}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq5sb__3TEDX",
        "colab_type": "code",
        "outputId": "f0802b04-19f3-4ed0-b746-b19dfc2e49ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "To feed the text into our Bi-LSTM-CRF, all texts should be the same length. \n",
        "used the sequence.pad_sequences() method and MAX_LEN variable.\n",
        "All texts longer than MAX_LEN are truncated and shorter texts are padded to get them to the same length\n",
        "\"\"\"\n",
        "# Convert each sentence from list of Token to list of word_index\n",
        "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
        "# Padding each sentence to have the same lenght\n",
        "X = pad_sequences(maxlen=MAX_LEN, sequences=X, padding=\"post\", value=word2idx[\"PAD\"])\n",
        "\n",
        "# Convert Tag/Label to tag_index\n",
        "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
        "# Padding each sentence to have the same lenght\n",
        "y = pad_sequences(maxlen=MAX_LEN, sequences=y, padding=\"post\", value=tag2idx[\"PAD\"])\n",
        "\n",
        "# One-Hot encode\n",
        "y = [to_categorical(i, num_classes=n_tags+1) for i in y]  # n_tags+1(PAD)\n",
        "\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)\n",
        "X_tr.shape, X_te.shape, np.array(y_tr).shape, np.array(y_te).shape\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1305, 15), (145, 15), (1305, 15, 6), (145, 15, 6))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz8IrBxtTEDc",
        "colab_type": "code",
        "outputId": "e43a461c-be67-45a3-fb68-82898c07720a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "# Model definition\n",
        "input = Input(shape=(MAX_LEN,))\n",
        "model = Embedding(input_dim=n_words+2, output_dim=EMBEDDING, input_length=MAX_LEN, mask_zero=True)(input)  # default: 20-dim embedding\n",
        "model = Bidirectional(LSTM(units=50, return_sequences=True, recurrent_dropout=0.1))(model)  # variational biLSTM\n",
        "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)\n",
        "crf = CRF(n_tags+1)  # CRF layer, n_tags+1(PAD)\n",
        "out = crf(model)  # output\n",
        "\n",
        "model = Model(input, out)\n",
        "model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2974: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 15, 40)            157040    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 15, 100)           36400     \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 15, 50)            5050      \n",
            "_________________________________________________________________\n",
            "crf_1 (CRF)                  (None, 15, 6)             354       \n",
            "=================================================================\n",
            "Total params: 198,844\n",
            "Trainable params: 198,844\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdgbHJQ_TEDi",
        "colab_type": "code",
        "outputId": "3bafb515-d602-482c-bb61-192b2d57f9d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(X_tr, np.array(y_tr), batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.1, verbose=2)\n",
        "\n",
        "#to save the model\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model_road_bld.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 1174 samples, validate on 131 samples\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            " - 4s - loss: 3.5830 - crf_viterbi_accuracy: 0.0154 - val_loss: 3.5007 - val_crf_viterbi_accuracy: 0.0392\n",
            "Epoch 2/25\n",
            " - 1s - loss: 3.2446 - crf_viterbi_accuracy: 0.3264 - val_loss: 2.9692 - val_crf_viterbi_accuracy: 0.8233\n",
            "Epoch 3/25\n",
            " - 1s - loss: 2.6937 - crf_viterbi_accuracy: 0.8758 - val_loss: 2.6768 - val_crf_viterbi_accuracy: 0.8767\n",
            "Epoch 4/25\n",
            " - 1s - loss: 2.5191 - crf_viterbi_accuracy: 0.8919 - val_loss: 2.6112 - val_crf_viterbi_accuracy: 0.8792\n",
            "Epoch 5/25\n",
            " - 1s - loss: 2.4467 - crf_viterbi_accuracy: 0.8922 - val_loss: 2.5645 - val_crf_viterbi_accuracy: 0.8792\n",
            "Epoch 6/25\n",
            " - 1s - loss: 2.3911 - crf_viterbi_accuracy: 0.8921 - val_loss: 2.5233 - val_crf_viterbi_accuracy: 0.8792\n",
            "Epoch 7/25\n",
            " - 1s - loss: 2.3451 - crf_viterbi_accuracy: 0.8921 - val_loss: 2.4885 - val_crf_viterbi_accuracy: 0.8792\n",
            "Epoch 8/25\n",
            " - 1s - loss: 2.3030 - crf_viterbi_accuracy: 0.8921 - val_loss: 2.4611 - val_crf_viterbi_accuracy: 0.8792\n",
            "Epoch 9/25\n",
            " - 1s - loss: 2.2667 - crf_viterbi_accuracy: 0.8924 - val_loss: 2.4378 - val_crf_viterbi_accuracy: 0.8792\n",
            "Epoch 10/25\n",
            " - 1s - loss: 2.2352 - crf_viterbi_accuracy: 0.8920 - val_loss: 2.4138 - val_crf_viterbi_accuracy: 0.8792\n",
            "Epoch 11/25\n",
            " - 1s - loss: 2.2080 - crf_viterbi_accuracy: 0.8921 - val_loss: 2.3957 - val_crf_viterbi_accuracy: 0.8792\n",
            "Epoch 12/25\n",
            " - 1s - loss: 2.1821 - crf_viterbi_accuracy: 0.8922 - val_loss: 2.3848 - val_crf_viterbi_accuracy: 0.8792\n",
            "Epoch 13/25\n",
            " - 1s - loss: 2.1585 - crf_viterbi_accuracy: 0.8928 - val_loss: 2.3699 - val_crf_viterbi_accuracy: 0.8792\n",
            "Epoch 14/25\n",
            " - 1s - loss: 2.1367 - crf_viterbi_accuracy: 0.8934 - val_loss: 2.3576 - val_crf_viterbi_accuracy: 0.8792\n",
            "Epoch 15/25\n",
            " - 1s - loss: 2.1135 - crf_viterbi_accuracy: 0.8949 - val_loss: 2.3491 - val_crf_viterbi_accuracy: 0.8783\n",
            "Epoch 16/25\n",
            " - 1s - loss: 2.0935 - crf_viterbi_accuracy: 0.8963 - val_loss: 2.3366 - val_crf_viterbi_accuracy: 0.8792\n",
            "Epoch 17/25\n",
            " - 1s - loss: 2.0742 - crf_viterbi_accuracy: 0.8992 - val_loss: 2.3430 - val_crf_viterbi_accuracy: 0.8775\n",
            "Epoch 18/25\n",
            " - 1s - loss: 2.0572 - crf_viterbi_accuracy: 0.9029 - val_loss: 2.3315 - val_crf_viterbi_accuracy: 0.8825\n",
            "Epoch 19/25\n",
            " - 1s - loss: 2.0448 - crf_viterbi_accuracy: 0.9053 - val_loss: 2.3492 - val_crf_viterbi_accuracy: 0.8800\n",
            "Epoch 20/25\n",
            " - 1s - loss: 2.0282 - crf_viterbi_accuracy: 0.9091 - val_loss: 2.3432 - val_crf_viterbi_accuracy: 0.8858\n",
            "Epoch 21/25\n",
            " - 1s - loss: 2.0166 - crf_viterbi_accuracy: 0.9098 - val_loss: 2.3670 - val_crf_viterbi_accuracy: 0.8825\n",
            "Epoch 22/25\n",
            " - 1s - loss: 2.0094 - crf_viterbi_accuracy: 0.9102 - val_loss: 2.3583 - val_crf_viterbi_accuracy: 0.8833\n",
            "Epoch 23/25\n",
            " - 1s - loss: 1.9966 - crf_viterbi_accuracy: 0.9138 - val_loss: 2.3908 - val_crf_viterbi_accuracy: 0.8775\n",
            "Epoch 24/25\n",
            " - 1s - loss: 1.9875 - crf_viterbi_accuracy: 0.9156 - val_loss: 2.3893 - val_crf_viterbi_accuracy: 0.8767\n",
            "Epoch 25/25\n",
            " - 1s - loss: 1.9816 - crf_viterbi_accuracy: 0.9174 - val_loss: 2.4120 - val_crf_viterbi_accuracy: 0.8833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmrdma1FTEDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Eval\n",
        "pred_cat = model.predict(X_te)\n",
        "pred = np.argmax(pred_cat, axis=-1)\n",
        "y_te_true = np.argmax(y_te, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-i3UwWMTEDp",
        "colab_type": "code",
        "outputId": "609148f3-d9aa-41b1-dd43-646ad88d47cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Convert the index to tag\n",
        "pred_tag = [[idx2tag[i] for i in row] for row in pred]\n",
        "y_te_true_tag = [[idx2tag[i] for i in row] for row in y_te_true] \n",
        "\n",
        "report = flat_classification_report(y_pred=pred_tag, y_true=y_te_true_tag)\n",
        "print(report)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-BLD       0.00      0.00      0.00        19\n",
            "       B-RAD       0.08      0.05      0.06        20\n",
            "       I-BLD       0.20      0.03      0.06        31\n",
            "       I-RAD       0.31      0.29      0.30        34\n",
            "           O       0.94      0.98      0.96      1133\n",
            "         PAD       1.00      1.00      1.00       938\n",
            "\n",
            "    accuracy                           0.95      2175\n",
            "   macro avg       0.42      0.39      0.40      2175\n",
            "weighted avg       0.93      0.95      0.94      2175\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gim3i18rw6dK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#formatting the output \n",
        "def getPredSentValue(passedVal):\n",
        "  tempPredList = []\n",
        "  pre_list = []\n",
        "  for i in range(15):\n",
        "    for j in range(6):\n",
        "      tempPredList.append(int(passedVal[i][j]))\n",
        "    tempPredList = np.asarray(tempPredList)\n",
        "  \n",
        "    product = emp.dot(tempPredList)\n",
        "    pre_val = inv_tag.get(product)\n",
        "    pre_list.append(pre_val)\n",
        "    tempPredList = []\n",
        "  res = dict(zip(s, pre_list)) \n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAJ8T0xqU9IS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to get the predicted sentence\n",
        "def getSentList(works_list):\n",
        "  sent_by_words = []\n",
        "  for i in range(15):\n",
        "    temp_l_word = works_list[i]\n",
        "    sent_by_words.append(inv_map.get(temp_l_word))\n",
        "  return sent_by_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ2G44i0L_3O",
        "colab_type": "code",
        "outputId": "7b903ac7-6bce-4644-eea8-e1687e4947f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#to convert tags in numpy array\n",
        "emp = []\n",
        "for ta in inv_tag.keys():\n",
        "  emp.append(ta)\n",
        "emp.remove(0)\n",
        "emp.insert(0,0)\n",
        "emp = np.asarray(emp)\n",
        "emp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g58SUwXcMFwC",
        "colab_type": "code",
        "outputId": "bcaf6a12-ddce-4bf4-c481-2b7ab7719c27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n = 0\n",
        "temp = model.predict(X_te)\n",
        "passed_val = temp[n].tolist()\n",
        "s=getSentList(X_te[n])\n",
        "res = getPredSentValue(passed_val)\n",
        "print(res)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'f-a603': 'O', '45': 'O', 'new': 'O', 'eskaton': 'O', 'beside': 'O', 'biam': 'I-RAD', 'off': 'B-BLD', 'PAD': 'PAD'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axsjY2BKNee-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bbc7b57d-7bea-439c-f433-bb26a2a499a3"
      },
      "source": [
        "n = 5\n",
        "temp = model.predict(X_te)\n",
        "passed_val = temp[n].tolist()\n",
        "s=getSentList(X_te[n])\n",
        "res = getPredSentValue(passed_val)\n",
        "print(res)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'34': 'O', 'arambag': 'O', 'motijhil': 'O', 'PAD': 'PAD'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx76tEgcNlSO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8eef86c2-f8dd-440c-9731-87d560817561"
      },
      "source": [
        "n = 137\n",
        "temp = model.predict(X_te)\n",
        "passed_val = temp[n].tolist()\n",
        "s=getSentList(X_te[n])\n",
        "res = getPredSentValue(passed_val)\n",
        "print(res)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'house-26/15': 'O', ',': 'O', 'haque': 'O', 'villa': 'I-RAD', 'flat-4/c': 'O', 'middle': 'O', 'paikpara': 'O', 'mirpur-1': 'O', 'PAD': 'PAD'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrDU_hQvVlvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inverting word2idx and tag2idx values\n",
        "inv_map = {v: k for k, v in word2idx.items()}\n",
        "inv_tag = {v: k for k, v in tag2idx.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}